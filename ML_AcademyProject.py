# -*- coding: utf-8 -*-
"""ml_project1_(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OGU1OHbb0jdY08QXM_QqRVPlNd2J_xEH

# **ML Academy - Project 1**
"""

from google.colab import drive
drive.mount('/content')

"""# **2. Import libraries** <a class="anchor" id="5"></a>"""

# import
import os
import zipfile
import pandas as pd
import numpy as np
import seaborn as sb
import seaborn as sns
import matplotlib.pyplot as plt #For plotting graphs

"""# **3. Load Data** <a class="anchor" id="5"></a>

"""

client_train  =  pd.read_csv('/content/client_train.csv')
invoice_train =  pd.read_csv('/content/invoice_train.csv')

dataFrame = pd.merge(client_train, invoice_train)

"""# **3. Exploratory data analysis** <a class="anchor" id="7"></a>



"""

dataFrame.shape

dataFrame.head()

col_names = dataFrame.columns
col_names

dataFrame.info()

categorical = [var for var in dataFrame.columns if dataFrame[var].dtype=='O']
print('There are {} categorical variables\n'.format(len(categorical)))
print('The categorical variables are :', categorical)

dataFrame[categorical].head()

"""### Missing values in categorical variables"""

# check missing values in categorical variables

dataFrame[categorical].isnull().sum()

for var in categorical:
    print(dataFrame[var].value_counts())
    print("\n===========================\n")

# check for cardinality in categorical variables

for var in categorical:

    print(var, ' contains ', len(dataFrame[var].unique()), ' labels')

"""### Feature Engineering"""

dataFrame['creation_date'].dtypes

if not pd.api.types.is_datetime64_any_dtype(dataFrame['creation_date']):
    # Convert column to a datetime format
    dataFrame['creation_date'] = pd.to_datetime(dataFrame['creation_date'])

dataFrame.info()

(dataFrame.creation_date).describe()

dataFrame['year_creation_date'] = dataFrame['creation_date'].dt.year
dataFrame['year_creation_date'].head()

len(dataFrame['year_creation_date'].unique())

dataFrame['Month_creation_date'] = dataFrame['creation_date'].dt.month
dataFrame['Month_creation_date'].head()

dataFrame['Day_creation_date'] = dataFrame['creation_date'].dt.day
dataFrame['Day_creation_date'].head()

pd.to_datetime(dataFrame.creation_date).describe()

dataFrame.drop('creation_date', axis=1, inplace = True)

dataFrame.head()

dataFrame['invoice_date'].dtypes

if not pd.api.types.is_datetime64_any_dtype(dataFrame['invoice_date']):
    # Convert date column to a datetime format
    dataFrame['invoice_date'] = pd.to_datetime(dataFrame['invoice_date'])

(dataFrame.invoice_date).describe()

dataFrame['year_invoice_date'] = dataFrame['invoice_date'].dt.year
dataFrame['year_invoice_date'].head()

len(dataFrame['year_invoice_date'].unique())

dataFrame['Month_invoice_date'] = dataFrame['invoice_date'].dt.month
dataFrame['Month_invoice_date'].head()

dataFrame['Day_invoice_date'] = dataFrame['invoice_date'].dt.day
dataFrame['Day_invoice_date'].head()

dataFrame.drop('invoice_date', axis=1, inplace = True)

print('Unique counter_statue :', dataFrame['counter_statue'].nunique())

print("Unique values of counter_statue" , dataFrame['counter_statue'].unique())

print('Count samples for each value :\n', dataFrame['counter_statue'].value_counts())

dataFrame['counter_statue'] = [0 if i == '0' else i for i in dataFrame['counter_statue']]
dataFrame['counter_statue'] = [1 if i == '1' else i for i in dataFrame['counter_statue']]
dataFrame['counter_statue'] = [4 if i == '4' else i for i in dataFrame['counter_statue']]
dataFrame['counter_statue'] = [5 if i == '5' else i for i in dataFrame['counter_statue']]
dataFrame['counter_statue'] = [4 if i ==  5  else i for i in dataFrame['counter_statue']]

print('Unique values of counter_statue: ' , dataFrame['counter_statue'].unique())

dataFrame.shape

values_to_drop = ['A', 618, 269375, 46, 420 , 769]
dataFrame = dataFrame[~dataFrame['counter_statue'].isin(values_to_drop)]

dataFrame.shape

print('counter_type contains', len(dataFrame['counter_type'].unique()), 'labels')

dataFrame['counter_type'].unique()

dataFrame.counter_type.value_counts()

"""----------------------------

### Explore Numerical Variables
"""

numerical = [var for var in dataFrame.columns if dataFrame[var].dtype!='O']
print('There are {} numerical variables\n'.format(len(numerical)))
print('The numerical variables are :', numerical)

dataFrame[numerical].head()

def univariate_categorical(feature,df=dataFrame,target='target',ylog=False,label_rotation=False,horizontal_layout=True):
    temp = df[feature].value_counts()
    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})

    # Calculate the percentage of target=1 per category value
    cat_perc = df[[feature, target]].groupby([feature],as_index=False).mean()
    cat_perc[target] = cat_perc[target]*100
    cat_perc.sort_values(by=target, ascending=False, inplace=True)

    if(horizontal_layout):
        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20,6))
    else:
        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(20,24))

    # 1. Subplot 1: Count plot of categorical column
    # sns.set_palette("Set2")
    s = sns.countplot(ax=ax1,
                    x = feature,
                    data=df,
                    hue =target,
                    order=cat_perc[feature]
                    #palette=['g','r']
                      )

    # Define common styling
    ax1.set_title(feature, fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Black'})
    ax1.legend(['Not fraud','Fraud'])

    # If the plot is not readable, use the log scale.
    if ylog:
        ax1.set_yscale('log')
        ax1.set_ylabel("Count (log)",fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Black'})


    if(label_rotation):
        s.set_xticklabels(s.get_xticklabels(),rotation=90)

    # 2. Subplot 2: Percentage of Fraud within the categorical column
    s = sns.barplot(ax=ax2,
                    x = feature,
                    y=target,
                    order=cat_perc[feature],
                    data=cat_perc
                    #palette='Set2'
                    )

    if(label_rotation):
        s.set_xticklabels(s.get_xticklabels(),rotation=90)
    plt.ylabel('Percent of Fraud [%]', fontsize=10)
    plt.tick_params(axis='both', which='major', labelsize=10)
    ax2.set_title(feature + " Fraud %", fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Black'})

    plt.show()

univariate_categorical('counter_type', df=dataFrame)

univariate_categorical('client_catg')

univariate_categorical('region', horizontal_layout=False)

dataFrame.groupby('region')['client_id'].count().sort_values(ascending=True).head(7)

univariate_categorical('counter_statue', df=dataFrame)

"""### Outliers in numerical variables"""

#summary statistics
print(round(dataFrame[numerical].describe()),2)

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.boxplot(column='disrict')
fig.set_title('')
fig.set_ylabel('disrict')

plt.subplot(2, 2, 2)
fig = dataFrame.boxplot(column='client_catg')
fig.set_title('')
fig.set_ylabel('client_catg')

plt.subplot(2, 2, 3)
fig = dataFrame.boxplot(column='tarif_type')
fig.set_title('')
fig.set_ylabel('tarif_type')

plt.subplot(2, 2, 4)
fig = dataFrame.boxplot(column='counter_number')
fig.set_title('')
fig.set_ylabel('counter_number')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.boxplot(column='counter_code')
fig.set_title('')
fig.set_ylabel('counter_code')

plt.subplot(2, 2, 2)
fig = dataFrame.boxplot(column='reading_remarque')
fig.set_title('')
fig.set_ylabel('reading_remarque')

plt.subplot(2, 2, 3)
fig = dataFrame.boxplot(column='counter_coefficient')
fig.set_title('')
fig.set_ylabel('counter_coefficient')

plt.subplot(2, 2, 4)
fig = dataFrame.boxplot(column='consommation_level_1')
fig.set_title('')
fig.set_ylabel('consommation_level_1')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.boxplot(column='consommation_level_2')
fig.set_title('')
fig.set_ylabel('consommation_level_2')

plt.subplot(2, 2, 2)
fig = dataFrame.boxplot(column='consommation_level_4')
fig.set_title('')
fig.set_ylabel('consommation_level_4')

plt.subplot(2, 2, 3)
fig = dataFrame.boxplot(column='consommation_level_3')
fig.set_title('')
fig.set_ylabel('consommation_level_3')

plt.subplot(2, 2, 4)
fig = dataFrame.boxplot(column='old_index')
fig.set_title('')
fig.set_ylabel('old_index')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.boxplot(column='new_index')
fig.set_title('')
fig.set_ylabel('new_index')

plt.subplot(2, 2, 2)
fig = dataFrame.boxplot(column='months_number')
fig.set_title('')
fig.set_ylabel('months_number')

IQR = dataFrame.consommation_level_1.quantile(0.75) - dataFrame.consommation_level_1.quantile(0.25)
Lower_fence = dataFrame.consommation_level_1.quantile(0.25) - (IQR * 3)
Upper_fence = dataFrame.consommation_level_1.quantile(0.75) + (IQR * 3)
print('consommation_level_1 outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))

"""### Distribution of variables"""

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.disrict.hist(bins=10)
fig.set_xlabel('disrict')

plt.subplot(2, 2, 2)
fig = dataFrame.client_catg.hist(bins=[11,12,13, 51, 52])
fig.set_xlabel('client_catg')

plt.subplot(2, 2, 3)
fig = dataFrame.target.hist(bins=10)
fig.set_xlabel('target')

plt.subplot(2, 2, 4)
fig = dataFrame.region.hist(bins=10)
fig.set_xlabel('region')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.months_number.hist(bins=10)
fig.set_xlabel('months_number')

plt.subplot(2, 2, 2)
fig = dataFrame.tarif_type.hist(bins=10)
fig.set_xlabel('tarif_type')

plt.subplot(2, 2, 3)
fig = dataFrame.counter_number.hist(bins=10)
fig.set_xlabel('counter_number')

plt.subplot(2, 2, 4)
fig = dataFrame.counter_code.hist(bins=10)
fig.set_xlabel('counter_code')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.reading_remarque.hist(bins=10)
fig.set_xlabel('reading_remarque')

plt.subplot(2, 2, 2)
fig = dataFrame.counter_coefficient.hist(bins=10)
fig.set_xlabel('counter_coefficient')

plt.subplot(2, 2, 3)
fig = dataFrame.consommation_level_1.hist(bins=10)
fig.set_xlabel('consommation_level_1')

plt.subplot(2, 2, 4)
fig = dataFrame.consommation_level_2.hist(bins=10)
fig.set_xlabel('consommation_level_2')

plt.figure(figsize=(15,10))

plt.subplot(2, 2, 1)
fig = dataFrame.consommation_level_3.hist(bins=10)
fig.set_xlabel('consommation_level_3')

plt.subplot(2, 2, 2)
fig = dataFrame.consommation_level_4.hist(bins=10)
fig.set_xlabel('consommation_level_4')

plt.subplot(2, 2, 3)
fig = dataFrame.old_index.hist(bins=10)
fig.set_xlabel('old_index')

plt.subplot(2, 2, 4)
fig = dataFrame.new_index.hist(bins=10)
fig.set_xlabel('new_index')

ds = dataFrame.groupby(['target'])['client_id'].count()
percentages = [100 * count / sum(ds) for count in ds]

colors = ['steelblue', 'darkorange']
fig, ax = plt.subplots(figsize=(8, 6))
ax.bar(x=['0', '1'], height=ds.values, color=colors)

# Add axis labels and a title
ax.set_xlabel('Target variable')
ax.set_ylabel('Number of clients')
ax.set_title('Distribution of target variable')

# Add a legend
#ax.legend(['Honest','Fraud'])
ax.legend(['Honest','Fraud'])

# Add percentage labels above each bar
for i, v in enumerate(percentages):
    ax.text(i, ds.values[i]+50, f'{v:.1f}%', ha='center')

# Show the plot of fraud vs non fraud
plt.show()

# Calculate the percentage of frauds by region
fraud_pct = dataFrame.groupby("counter_statue")["target"].mean() * 100

# Create a bar chart using Matplotlib
fig, ax = plt.subplots(figsize=(12, 6))
fraud_pct.plot(kind="bar", ax=ax, color="blue")
ax.set_xlabel("counter_statue")
ax.set_ylabel("Percentage of Frauds")
ax.set_title("Target vs counter_statue")
plt.show()

cols = ['disrict','client_catg' , 'region' , 'tarif_type' , 'counter_statue' ,'reading_remarque',
       'counter_coefficient', 'counter_type']

for col in cols:
    print('Count samples for each value :\n', dataFrame[col].value_counts())
    print('\n',dataFrame.groupby([col, 'target']).size())
    print("=================================")

cols = ['disrict','client_catg','region']
plt.clf()
plt.figure(figsize=(10, 20))
for i, col in enumerate(cols):
    plt.subplot(len(cols),1, i+1)
    sns.countplot(x=col, data=dataFrame, hue='target')
plt.show()

"""### Heatmap"""

df_corr = pd.DataFrame(dataFrame.corr())
df_corr['target'].sort_values(ascending=False)

import seaborn as sns
fig, ax=plt.subplots()
fig.set_size_inches(25,15)
sns.heatmap(dataFrame.corr(),square=True, annot=True,cmap='YlGnBu')
plt.title('Correlation of df Features\n',fontsize=20  );

import plotly.graph_objs as go
fraud_data_sample = dataFrame.sample(n=1000, random_state=42)
honest_data_sample = dataFrame.sample(n=1000, random_state=42)

# Calculate the average values for different invoice features
fraudulent_means = fraud_data_sample[['tarif_type', 'counter_number', 'counter_statue', 'counter_code',
                                      'counter_coefficient', 'consommation_level_1', 'consommation_level_2',
                                      'consommation_level_3', 'consommation_level_4', 'old_index', 'new_index']].mean()
non_fraudulent_means = honest_data_sample[['tarif_type', 'counter_number', 'counter_statue', 'counter_code',
                                            'counter_coefficient', 'consommation_level_1', 'consommation_level_2',
                                            'consommation_level_3', 'consommation_level_4', 'old_index', 'new_index']].mean()

fig = go.Figure()
fig.add_trace(go.Scatterpolar(
      r=fraudulent_means.values,
      theta=fraudulent_means.index,
      fill='toself',
      name='Fraudulent'
))
fig.add_trace(go.Scatterpolar(
      r=non_fraudulent_means.values,
      theta=non_fraudulent_means.index,
      fill='toself',
      name='Non-Fraudulent'
))

fig.update_layout(
  polar=dict(
    radialaxis=dict(
      visible=True,
      range=[0, 500] # set the range based on the data
    )),
  showlegend=True
)
fig.show()

"""# **4. Declare feature vector and target variable** <a class="anchor" id="8"></a>


[Table of Contents](#0.1)
"""

df_NF = dataFrame[dataFrame['target']== 0.0]
df_NF.shape

df_F = dataFrame[dataFrame['target']== 1.0]
df_F.shape

df_downsampled = df_NF.sample(df_F.shape[0])
df_downsampled.shape

df_F = dataFrame[dataFrame['target']== 1.0]
df_F.shape

df_balanced = pd.concat([df_downsampled, df_F])
df_balanced.shape

numerical

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from keras.metrics import Accuracy

df = pd.DataFrame()

# preprocess the data
numeric_features = ['disrict', 'client_catg', 'region',  'tarif_type', 'counter_number', 'counter_code', 'reading_remarque', 'counter_coefficient', 'consommation_level_1',
                    'consommation_level_2','consommation_level_3','consommation_level_4', 'old_index','new_index','months_number', 'year_creation_date', 'Month_creation_date',
                    'Day_creation_date', 'year_invoice_date', 'Month_invoice_date', 'Day_invoice_date']

categorical_features = ['client_id', 'counter_statue', 'counter_type']

numeric_transformer = StandardScaler()
categorical_transformer = LabelEncoder()

df[numeric_features] = numeric_transformer.fit_transform(df_balanced[numeric_features])

for feature in categorical_features:
    df[feature] = categorical_transformer.fit_transform(df_balanced[feature])

"""['disrict', 'client_catg', 'region',  'tarif_type', 'counter_number', 'counter_code', 'reading_remarque', 'counter_coefficient', 'consommation_level_1',
                    'consommation_level_2','consommation_level_3','consommation_level_4', 'old_index','new_index','months_number', 'year_creation_date', 'Month_creation_date',
                    'Day_creation_date', 'year_invoice_date', 'Month_invoice_date', 'Day_invoice_date']
"""

# split the data
X_train, X_test, y_train, y_test = train_test_split(df[['disrict' , 'client_id']], df_balanced['target'], test_size=0.2, random_state=42)

db = df_balanced.groupby(['target'])['client_id'].count()
percentages = [100 * count / sum(db) for count in db]

colors = ['steelblue', 'darkorange']
fig, ax = plt.subplots(figsize=(8, 6))
ax.bar(x=['0', '1'], height=db.values, color=colors)

# Add axis labels and a title
ax.set_xlabel('Target variable')
ax.set_ylabel('Number of clients')
ax.set_title('Distribution of target variable')

# Add a legend
#ax.legend(['Category 0',
#           'Category 1'])

# Add percentage labels above each bar
for i, v in enumerate(percentages):
    ax.text(i, db.values[i]+50, f'{v:.1f}%', ha='center')

# Show the plot of fraud vs non fraud
plt.show()

"""### KNeighborsClassifier model"""

#K-NN classifier
from sklearn.neighbors import KNeighborsClassifier
classifier= KNeighborsClassifier(n_neighbors=5,  p=2 )
classifier.fit(X_train, y_train)

y_pred= classifier.predict(X_test)

from sklearn import metrics
print(metrics.accuracy_score(y_test, y_pred))

"""# **5. Check the accuracy** <a class="anchor" id="14"></a>"""

from sklearn.metrics import accuracy_score
print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

y_pred_train = classifier.predict(X_train)
y_pred_train

print('Training-set accuracy score: {0:0.4f}'.format(accuracy_score(y_train, y_pred_train)))

print('Training set score: {:.4f}'.format(classifier.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(classifier.score(X_test, y_test)))

"""# **6. Confusion matrix** <a class="anchor" id="15"></a>"""

from sklearn.metrics import confusion_matrix
cm1 = confusion_matrix(y_test, y_pred)
print('Confusion matrix\n\n', cm1)
print('\nTrue Positives(TP) = ', cm1[0,0])
print('\nTrue Negatives(TN) = ', cm1[1,1])
print('\nFalse Positives(FP) = ', cm1[0,1])
print('\nFalse Negatives(FN) = ', cm1[1,0])

cm_matrix = pd.DataFrame(data=cm1, columns=['Actual Positive:1', 'Actual Negative:0'],
                                 index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

"""# **7. Classification metrices** <a class="anchor" id="16"></a>"""

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""-----------------------"""

X_train, X_test, y_train, y_test = train_test_split(df[['disrict',  'region',  'tarif_type', 'counter_type', 'counter_code', 'counter_statue','counter_coefficient',
                    'consommation_level_3','months_number', 'year_invoice_date', 'client_id']], df_balanced['target'], test_size=0.2, random_state=42)

"""['disrict', 'client_catg', 'region',  'tarif_type', 'counter_number', 'counter_code', 'reading_remarque', 'counter_coefficient', 'consommation_level_1',
                    'consommation_level_2','consommation_level_3','consommation_level_4', 'old_index','new_index','months_number', 'year_creation_date', 'Month_creation_date',
                    'Day_creation_date', 'year_invoice_date', 'Month_invoice_date', 'Day_invoice_date']
                    ['client_id', 'counter_statue', 'counter_type'

### Random Forest Classifier
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score

rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(X_train, y_train)

#y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

y_pred = rf_model.predict(X_test)
#accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)

#print("Accuracy: ", accuracy)
print("ROC AUC: ", roc_auc)

from sklearn.metrics import confusion_matrix
cm2 = confusion_matrix(y_test, y_pred)
print('Confusion matrix\n\n', cm2)
print('\nTrue Positives(TP) = ', cm2[0,0])
print('\nTrue Negatives(TN) = ', cm2[1,1])
print('\nFalse Positives(FP) = ', cm2[0,1])
print('\nFalse Negatives(FN) = ', cm2[1,0])

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

y_pred_proba

def Visualize_Distribution(df,column):
  plt.hist(df[column])
  plt.title('Distribution of ' + column)
  plt.xlabel(column)
  plt.ylabel('Count')
  plt.show()

def Visualize_relationship(df ,column1, column2 ):
  plt.scatter(df[column1], df[column2])
  plt.title(column1 + ' vs. ' + column2)
  plt.xlabel(column1)
  plt.ylabel(column2)
  plt.show()

def v(df, col1 , col2 = 'target'):
  grouped = df.groupby([col1, col2]).size().unstack()

  plt.figure(figsize=(8, 6))
  grouped.plot(kind='bar', position=0.5, width=0.4)
  plt.title('Frequency of Target by Region')
  plt.xlabel('Region')
  plt.ylabel('Frequency')
  plt.show()

from sklearn import metrics
print(metrics.accuracy_score(y_test, y_pred))

rf_model.predict_proba(X_test)[:,0]

y_train

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""### Logistic Regression Classifier"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

#y_pred_proba = lr_model.predict_proba(X_test)[:, 1]
y_pred = lr_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)

print("Accuracy: ", accuracy)
print("ROC AUC: ", roc_auc)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion matrix\n\n', cm)
print('\nTrue Positives(TP) = ', cm[0,0])
print('\nTrue Negatives(TN) = ', cm[1,1])
print('\nFalse Positives(FP) = ', cm[0,1])
print('\nFalse Negatives(FN) = ', cm[1,0])

cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],
                                 index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier

#lr_model = LogisticRegression(solver="liblinear", random_state=42)
#rf_model = RandomForestClassifier(n_estimators=10, random_state=42)
#knn_model = KNeighborsClassifier()

voting = VotingClassifier(
    estimators=[('lr', lr_model), ('rf', rf_model), ('knn', classifier)],
    voting='hard')

voting_clf = voting.fit(X_train, y_train)

from sklearn.metrics import accuracy_score

for clf in (lr_model, rf_model, classifier):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))

models = []
models.append(('Knn', KNeighborsClassifier()))
models.append(('LR', LogisticRegression()))
models.append(('RF', RandomForestClassifier()))
#models.append(('EL', VotingClassifier(
    #estimators=[('lr', lr_model), ('rf', rf_model), ('knn', classifier)],
    #voting='hard')))


names = []
scores = []
for name, model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    scores.append(accuracy_score(y_test, y_pred))
    names.append(name)
tr_split = pd.DataFrame({'Name': names, 'Score': scores})
print(tr_split)

import seaborn as sns
axis = sns.barplot(x = 'Name', y = 'Score', data =tr_split )
axis.set(xlabel='Classifier', ylabel='Accuracy')
for p in axis.patches:
    height = p.get_height()
    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha="center")

plt.show()